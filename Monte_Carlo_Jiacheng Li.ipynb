{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Econometrics Final Project - Monte-Carlo Replication of Stock and Watson (2008)\n",
    "Author: Jiacheng Li  \n",
    "Date: April 20, 2022\n",
    "\n",
    "This notebook replicates the Monte-Carlo experiment of Stock and Watson (2008).\n",
    "\n",
    "## Part 1. Model\n",
    "Consider the following fixed effect regression model.\n",
    "\n",
    "$$Y_{it}=\\alpha_{i}+\\beta^{\\prime}X_{it}+u_{it},\\quad i=1,\\ldots,n,\\quad t=1,\\ldots,T$$\n",
    "\n",
    "First, we define the “Within”-transformed variables, i.e., from which the time deviation is subtracted, as\n",
    "$$\\tilde{X}_{it}=X_{it}-T^{-1}\\sum_{s=1}^{T}X_{is}.$$\n",
    "\n",
    "And suppose $\\left(X_{it},u_{it}\\right)$ follow the below assumptions.\n",
    "\n",
    "Assumption 1. $\\left\\{ \\left(X_{it},u_{it}\\right)\\right\\} _{t=1}^{T}$ are i.i.d. over $i=1,...,n.$\n",
    "\n",
    "\n",
    "\n",
    "Assumption 2. $\\mathbb{E}\\left[u_{it}\\vert X_{it},...,X_{iT}\\right]=0.$\n",
    "\n",
    "\n",
    "\n",
    "Assumption 3. $Q_{\\tilde{X}\\tilde{X}}\\equiv\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\tilde{X}_{it}\\tilde{X}_{it}^{\\prime}\\right]$ is nonsingular.\n",
    "\n",
    "\n",
    "\n",
    "Assumption 4. $\\mathbb{E}\\left[u_{it}u_{is}\\vert X_{it},...,X_{iT}\\right]=0$ for $t\\neq s.$\n",
    "\n",
    "\n",
    "\n",
    "Assumption 5. $\\left(X_{it},u_{it}\\right)$ is stationary and has absolutely summable cumulants up to order 12.\n",
    "\n",
    "The fixed effect estimator is \n",
    "$$\\hat{\\beta}_{\\mathrm{FE}}=\\left(\\sum_{i=1}^{n}\\sum_{t=1}^{T}\\tilde{X}_{it}\\tilde{X}_{it}^{\\prime}\\right)^{-1}\\sum_{i=1}^{n}\\sum_{t=1}^{T}\\tilde{X}_{it}\\tilde{Y}_{it}.$$\n",
    "\n",
    "where $\\hat{\\tilde{u}}_{it}$ is the fixed effect regression residuals, i.e., \n",
    "$$\\hat{\\tilde{u}}_{it}=\\hat{\\tilde{Y}_{it}}-\\hat{\\beta}_{\\mathrm{FE}}^{\\prime}\\tilde{X}_{it}=\\tilde{u}_{it}-\\left(\\hat{\\beta}_{\\mathrm{FE}}-\\beta\\right)^{\\prime}\\tilde{X}_{it}.$$\n",
    "\n",
    "The paper considers and compares the following three heteroskedasticity-robust (HR) covariance estimators for fixed effect panel data regression:\n",
    "$$\\hat{\\Sigma}^{\\text{HR-XS}}\t=\\frac{1}{nT-n-k}\\sum_{i=1}^{n}\\sum_{t=1}^{T}\\tilde{X}_{it}\\tilde{X}_{it}^{\\prime}\\hat{\\tilde{u}}_{it}^{2} \\\\\n",
    "\\hat{\\Sigma}^{\\text{HR-FE}}\t=\\left(\\frac{T-1}{T-2}\\right)\\left(\\hat{\\Sigma}^{\\mathrm{HR}-\\mathrm{XS}}-\\frac{1}{T-1}\\hat{B}\\right) \\\\\n",
    "\\hat{\\Sigma}^{\\text{cluster}}\t=\\frac{1}{nT}\\sum_{i=1}^{n}\\left(\\sum_{t=1}^{T}\\tilde{X}_{it}\\hat{\\tilde{u}}_{it}\\right)\\left(\\sum_{s=1}^{T}\\tilde{X}_{is}\\hat{\\tilde{u}}_{is}\\right)^{\\prime}$$\n",
    "\n",
    "where $\\hat{B}=\\frac{1}{n}\\sum_{i=1}^{n}\\left(\\frac{1}{T}\\sum_{t=1}^{T}\\tilde{X}_{it}\\tilde{X}_{it}^{\\prime}\\right)\\left(\\frac{1}{T-1}\\sum_{s=1}^{T}\\hat{\\tilde{u}}_{is}^{2}\\right). $\n",
    "\n",
    "\n",
    "\n",
    "## Part 2. Monte Carlo Design\n",
    "The benchmark Monte Carlo design as specified in section 2 of the paper is as follows:\n",
    "\n",
    "$\\quad y_{i t}=x_{i t} \\beta+u_{i t}$\n",
    "\n",
    "$\\quad x_{i t}=\\zeta_{i t}+\\theta \\zeta_{i t-1}, \\quad \\zeta_{i t} \\sim$ i.i.d. $\\mathrm{N}(0,1), \\quad t=1, \\ldots, T$,\n",
    "\n",
    "$\\quad u_{i t}=\\varepsilon_{i t}+\\theta \\varepsilon_{i t-1}, \\quad \\varepsilon_{i t} \\mid x_{i} \\sim$ i.n.i.d. $\\mathrm{N}\\left(0, \\sigma_{i t}^{2}\\right), \\quad \\sigma_{i t}^{2}=\\lambda\\left(0.1+x_{i t}^{2}\\right)^{\\kappa}$, $t=1, \\ldots, T$,\n",
    "\n",
    "where $\\kappa=1,-1$ and $\\lambda$ is chosen so that $Var(\\epsilon_{it})=1$. \n",
    "\n",
    "#### Deriving $\\lambda_{1}, \\lambda_{2}$ in the Design\n",
    "\n",
    "Next, we find $\\lambda_{1},\\lambda_{2}$ for $\\kappa=1,-1$.\n",
    "\n",
    "Here, \n",
    "$$Var\\left(\\epsilon_{it}\\right)=\\mathbb{E}\\left[Var\\left(\\epsilon_{it}\\vert x_{i}\\right)\\right]+Var\\left(\\mathbb{E}\\left[\\epsilon_{it}\\vert x_{i}\\right]\\right)=\\mathbb{E}\\left[Var\\left(\\epsilon_{it}\\vert x_{i}\\right)\\right]=\\lambda\\mathbb{E}\\left[\\left(0.1+x_{it}^{2}\\right)^{\\kappa}\\right]=1.$$\n",
    "\n",
    "Since $\\theta=0, x_{it}=\\zeta_{it}\\sim\\text{N }(0,1)$ and $\\mathbb{E}\\left[x_{it}^{2}\\right]=Var\\left(x_{it}\\right)=1.$\n",
    "\n",
    "When $\\kappa=1$,\n",
    "$$\\lambda\\mathbb{E}\\left[\\left(0.1+x_{it}^{2}\\right)\\right]=\\lambda\\left(0.1+\\mathbb{E}\\left[x_{it}^{2}\\right]\\right)=1\\implies\\lambda=\\frac{1}{0.1+1}=\\frac{10}{11}.$$\n",
    "\n",
    "When $\\kappa=-1$, \n",
    "$$\\lambda\\mathbb{E}\\left[\\left(0.1+x_{it}^{2}\\right)^{-1}\\right]=1 $$\n",
    "where \n",
    "$$\\mathbb{E}\\left[\\frac{1}{\\left(0.1+x_{it}^{2}\\right)}\\right]=\\frac{1}{\\sqrt{2\\pi}}\\int_{\\mathbb{R}}\\frac{1}{\\left(0.1+x_{it}^{2}\\right)}e^{-\\frac{x^{2}}{2}}dx,\\quad x_{it}\\sim\\text{N}\\left(0,1\\right)$$\n",
    "Observe the identity $\\frac{1}{S}=\\int_{0}^{\\infty}e^{-tS}dt$.\n",
    "\n",
    "This allows us to write\n",
    "$$\\mathbb{E}\\left[\\frac{1}{\\left(0.1+x_{it}^{2}\\right)}\\right]=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty}\\int_{0}^{\\infty}e^{-t\\left(0.1+x_{it}^{2}\\right)}e^{-\\frac{x^{2}}{2}}dtdx$$\n",
    "Since $e^{-t\\left(0.1+x_{it}^{2}\\right)}e^{-\\frac{x^{2}}{2}}>0$, we can apply Fubini theorem, which yields,\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[\\frac{1}{\\left(0.1+x_{it}^{2}\\right)}\\right]&=\\frac{1}{\\sqrt{2\\pi}}\\int_{0}^{\\infty}\\int_{-\\infty}^{\\infty}e^{-t\\left(0.1+x_{it}^{2}\\right)}e^{-\\frac{x^{2}}{2}}dxdt\\\\\n",
    "&=\\frac{1}{\\sqrt{2\\pi}}\\int_{0}^{\\infty}e^{-0.1t}\\left(\\int_{-\\infty}^{\\infty}e^{-\\left(t+\\frac{1}{2}\\right)x_{it}^{2}}dx\\right)dt\\\\\n",
    "&=\\int_{0}^{\\infty}e^{-0.1t}\\left(1+2t\\right)^{-\\frac{1}{2}}dt\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lambda1\n",
    "lambda1 = 1.1\n",
    "\n",
    "# evaluate integral\n",
    "def f(x):\n",
    "    return np.exp(-1*x)*(1+2*x)**(-1/2)\n",
    "integ, err = quad(f, 0, np.inf)\n",
    "\n",
    "# get lambda2\n",
    "lambda2 = 1/integ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "This can be evaluted numerically and we get \n",
    "$$\\lambda=\\frac{1}{\\int_{0}^{\\infty}e^{-0.1t}\\left(1+2t\\right)^{-\\frac{1}{2}}dt}\\simeq 1.525135$$\n",
    "\n",
    "### Monte Carlo Experiments\n",
    "\n",
    "As there is only one regressor and one regressand, it is easy to define both X and Y as a $N \\times T$ matrix.\n",
    "\n",
    "The procedure for conducting Monte Carlo experiments is as follows:\n",
    "1. For each $(n, T)$, make $M$ Monte Carlo draws with the data-generating process parametrized as indicated above, for each $\\kappa = 1, -1$.\n",
    "2. Compute the three estimators: $\\hat{\\Sigma}^{\\text{HR-XS}}$, $\\hat{\\Sigma}^{\\text{HR-FE}}$, and $\\hat{\\Sigma}^{\\text{cluster }}$.\n",
    "3. Compute the Bias relative to the True $\\beta$ and MSE relative to the infeasible estimator: \n",
    "$$\\hat{\\Sigma^{i n f}}=(n T)^{-1} \\sum_{i=1}^{n} \\sum_{t=1}^{T} \\tilde{X}_{i t}^{2} u_{i t}^{2}.$$\n",
    "4. Compute the rates at which the null hypothesis, $\\beta = \\beta_{0}$ is rejected, using a two-sided test at a 10\\% critical level. Here we compute the $t$-statistic using each suggested variance estimator. For $\\hat{\\Sigma}^{\\text{HR-XS}}$, $\\hat{\\Sigma}^{\\text{HR-FE}}$, the critical value comes from a normal distribution; and for $\\hat{\\Sigma}^{\\text{cluster }}$, it follows the $\\sqrt{\\frac{n}{n-1}}t_{n-1}$ distribution.\n",
    "5. Summarize the results.\n",
    "\n",
    "<i>Note</i>: To simplify data generating and processing in a programming language, since the benchmark and follow-up Monte Carlo designs all only contain one single regressor, the panel data structure with double indexes allow us to store each variable in a matrix. \n",
    "\n",
    "I will create $(X, Y, u, \\zeta, \\epsilon, \\sigma)$ that are two-dimensional matrices where $(Z_{it})$ represents the $i$'th row, $j$'s column element, which is the observation of individual $i$ in $t=j$.\n",
    "\n",
    "First, I build the following functions that compute the Fixed Effect estimator and the proposed three types of HR variance covariance estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within operator\n",
    "def within(Z):\n",
    "    \"\"\"\n",
    "    Computes the resulting matrix by taking the deviation from the time average\n",
    "    \"\"\"\n",
    "    # get dimension\n",
    "    (N,T) = Z.shape\n",
    "\n",
    "    # first broadcast\n",
    "    time_mean = 1/T * Z.sum(axis=1, keepdims=True)\n",
    "    bc = np.tile(\n",
    "        time_mean, reps=(1,T)\n",
    "    )\n",
    "\n",
    "    # then within\n",
    "    return Z - bc\n",
    "\n",
    "\n",
    "# create functions to calculate FE estimator and HR covariance\n",
    "def Fixed_Effect(X,Y):\n",
    "    \"\"\"\n",
    "    Computes the fixed effect estimator given Y and X\n",
    "    \"\"\"\n",
    "    # get dimension\n",
    "    (N,T) = X.shape\n",
    "\n",
    "    # within transformation\n",
    "    X_tild, Y_tild = within(X), within(Y)\n",
    "\n",
    "    # compute FE estimator\n",
    "    beta_FE = np.sum(X_tild*Y_tild) / np.sum(X_tild**2)\n",
    "\n",
    "    # compute residual\n",
    "    res_FE = Y_tild - beta_FE*X_tild\n",
    "    return beta_FE, res_FE\n",
    "\n",
    "\n",
    "def HR_XS(res_FE, X_tild):\n",
    "    \"\"\"\n",
    "    Computes the HR-XS heteroskedasticity-robust (HR) covariance estimator\n",
    "    \"\"\"\n",
    "    # get dimension\n",
    "    (N,T) = X_tild.shape\n",
    "\n",
    "    # compute HR-XS vcov_hat\n",
    "    vcov_hat = 1/(N*T-N-1) * np.sum((X_tild**2)*(res_FE**2))\n",
    "    return vcov_hat\n",
    "\n",
    "\n",
    "def HR_FE(res_FE, X_tild):\n",
    "    \"\"\"\n",
    "    Computes the HR-FE heteroskedasticity-robust (HR) covariance estimator\n",
    "    \"\"\"\n",
    "    # get dimension\n",
    "    (N,T) = X_tild.shape\n",
    "\n",
    "    # get HR_XS vcov_hat\n",
    "    HR_XS_hat = HR_XS(res_FE, X_tild)\n",
    "\n",
    "    # calculate B_hat\n",
    "    B_hat1 = 1/T * np.sum(X_tild**2, axis=1, keepdims=True)\n",
    "    B_hat2 = 1/(T-1) * np.sum(res_FE**2, axis=1, keepdims=True)\n",
    "\n",
    "    B_hat = 1/N * np.sum(B_hat1 * B_hat2, axis=0)\n",
    "\n",
    "    # compute HR-FE vcov_hat\n",
    "    vcov_hat = ((T-1)/(T-2)) * (HR_XS_hat-1/(T-1)*B_hat)\n",
    "    return vcov_hat\n",
    "\n",
    "\n",
    "def cluster(res_FE, X_tild):\n",
    "    \"\"\"\n",
    "    Computes the clustered covariance estimator\n",
    "    \"\"\"\n",
    "    # get dimension\n",
    "    (N,T) = X_tild.shape\n",
    "\n",
    "    # this yields a N by 1 vector\n",
    "    T_sum = np.sum(X_tild*res_FE, axis=1)\n",
    "\n",
    "    # compute clustered vcov_hat\n",
    "    vcov_hat = 1/(N*T) * np.sum(T_sum**2)\n",
    "    return vcov_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I write a function that generates a Monte Carlo draw for a given $(n,T,\\kappa)$ tuple. \n",
    "\n",
    "Notice that the true variance is given by \n",
    "\n",
    "$$\\begin{align*} \n",
    "\\Sigma&=\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\tilde{X}_{it}\\tilde{X}_{it}'u_{it}^{2}\\right] \\\\\n",
    "& =\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\tilde{X}_{it}\\tilde{X}_{it}'\\mathbb{E}\\left[u_{it}^{2}\\vert X_{it}\\right]\\right] \\\\\n",
    "& =\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\tilde{X}_{it}^{2}\\sigma_{it}^{2}\\right] \\\\\n",
    "& =\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\left(X_{it}-\\frac{1}{T}\\sum_{s=1}^{T}X_{is}\\right)^{2}\\lambda\\left(0.1+X_{it}^{2}\\right)^{\\kappa}\\right]\\end{align*}\n",
    "\t$$\n",
    "\n",
    "since in our design $X_{it}$ is a scalar. This can be estimated below using a large sample to avoid analytical technicalities. That is, we separately simulate a $(X,\\tilde{X},\\sigma)$ tuple with a very large $n$ and appeal to the Law of Large Numbers to evalute the expectation through approximation. This is achieved by the following program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_true(kappa, T):\n",
    "    \"\"\"\n",
    "    Computes the true variance of beta using large sample approximation\n",
    "    \"\"\"\n",
    "    # create matrix\n",
    "    N = 10000\n",
    "    X = np.random.normal(loc=0, scale=1, size=[N,T])\n",
    "    X_tild = within(X)\n",
    "\n",
    "    # define kappa\n",
    "    if kappa==1:\n",
    "        Lambda = lambda1\n",
    "    elif kappa==-1:\n",
    "        Lambda = lambda2\n",
    "\n",
    "    # compute variance by appealing to LLN\n",
    "    To_sum = X_tild**2 * Lambda * (0.1 + X**2)**kappa\n",
    "    var = 1/T * 1/N * np.sum(To_sum)\n",
    "\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we propose the infeasible estimator \n",
    "\n",
    "$$\\hat{\\Sigma}^{\\text{inf}}=\\frac{1}{nT}\\sum_{i=1}^{n}\\sum_{t=1}^{T}\\tilde{X}_{it}^{2}u_{it}^{2}$$ \n",
    "where $u_{it}$ comes from the true data-generating process. \n",
    "\n",
    "For each Monte Carlo draw, we compute:\n",
    "- the Bias relateive to the true $\\Sigma$ of each estimator, \n",
    "- the Mean Squared Error (MSE) relative to the infeasible estimator, and \n",
    "- the rejection rates under the null hypothesis of the two-sided test of $\\beta = \\beta_{0}$ based on the t-statistic computed using\n",
    "the indicated variance estimator and the 10% asymptotic critical value.\n",
    "\n",
    "<i> Note: </i> using $\\hat{\\Sigma}^{\\text{HR-XS}}$ and $\\hat{\\Sigma}^{\\text{HR-FE}}$, the critical value is from the standard normal distribution, using $\\hat{\\Sigma}^{\\text{cluster}}$, it is from the $\\sqrt{\\frac{n}{n-1}}t_{n-1}$ distribution.\n",
    "\n",
    "Below I create functions that \n",
    "- compute the variance of $\\epsilon_{it}$ in the DGP conditional on $x_{it}$;\n",
    "- compute the true variance and infeasible estimator respectively;\n",
    "- compute the mean bias and MSE;\n",
    "- create a hypothesis testing procedure that takes a given variance estimator as input and computes the rejection rate under the null hypothesis and proposed criterion and test statistic.\n",
    "\n",
    "For hypothesis testing, recall that \n",
    "$$\n",
    "\\sqrt{n T}\\left(\\hat{\\beta}_{\\mathrm{FE}}-\\beta\\right) \\stackrel{d}{\\rightarrow} \\mathrm{N}\\left(0, Q_{\\tilde{X} \\tilde{X}}^{-1} \\Sigma Q_{\\tilde{X} \\tilde{X}}^{-1}\\right)\n",
    "$$\n",
    "where $\\quad \\Sigma=\\frac{1}{T} \\sum_{t=1}^{T} E\\left(\\tilde{X}_{i t} \\tilde{X}_{i t}^{\\prime} u_{i t}^{2}\\right)$. This implies\n",
    "$$\\hat{\\beta}_{FE}\\sim N\\left(\\beta,\\frac{1}{nT}Q_{\\tilde{X}\\tilde{X}}^{-1}\\Sigma Q_{\\tilde{X}\\tilde{X}}^{-1}\\right)$$\n",
    "And,$$\\frac{\\hat{\\beta}_{FE}-\\beta}{\\sqrt{\\frac{1}{nT}Q_{\\tilde{X}\\tilde{X}}^{-1}\\Sigma Q_{\\tilde{X}\\tilde{X}}^{-1}}}\\sim N\\left(0,1\\right)$$ \n",
    "where we replace $Q,\\Sigma$ by the sample counterpart and estimators to evaluate rejection size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_eps(Lambda, kappa, x):\n",
    "    \"\"\"\n",
    "    Computes the variance of eps | x\n",
    "    \"\"\"\n",
    "    return Lambda*(0.1+x**2)**kappa\n",
    "\n",
    "\n",
    "def var_inf(u, X_tild):\n",
    "    \"\"\"\n",
    "    Compute the proposed infeasible variance estimator\n",
    "    \"\"\"\n",
    "    # get dimension\n",
    "    (N,T) = X_tild.shape\n",
    "\n",
    "    mat = (X_tild**2) * (u**2)\n",
    "    return 1/(N*T)*np.sum(mat)\n",
    "\n",
    "\n",
    "def mean_bias(cov_hat, cov, N):\n",
    "    \"\"\"\n",
    "    Compute the mean bias of estimated variance\n",
    "    \"\"\"\n",
    "    return np.sum(cov_hat - cov) / N\n",
    "\n",
    "\n",
    "def RMSE(cov_hat, cov, N):\n",
    "    \"\"\"\n",
    "    Compute the RMSE of estimated variance\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.square(cov_hat - cov).sum() / N)\n",
    "    \n",
    "    \n",
    "def hypo_test(\n",
    "    var_hat, X_tild, beta_hat, beta,\n",
    "    est_name    # need estimator name to specify asymptotic distributions\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Conduct hypothesis testing for each estimator based on its asymptotic distribution\n",
    "    \"\"\"\n",
    "    # get dimension\n",
    "    (N,T) = X_tild.shape\n",
    "\n",
    "    Q_hat = 1/(N*T) * np.sum(X_tild**2)\n",
    "\n",
    "    # compute t-statistic\n",
    "    t_stat = (beta_hat-beta) / np.sqrt(\n",
    "        1/(N*T) * (1/Q_hat) * var_hat * (1/Q_hat)\n",
    "    )\n",
    "\n",
    "    # compute critical value at 10%\n",
    "    if est_name=='HR-XS':\n",
    "        crit_val = stats.norm.ppf(1-0.1/2)\n",
    "\n",
    "    elif est_name=='HR-FE':\n",
    "        crit_val = stats.norm.ppf(1-0.1/2)\n",
    "\n",
    "    elif est_name=='cluster':\n",
    "        crit_val = stats.t.ppf(\n",
    "            q=1-0.1/2,\n",
    "            df=N-1,\n",
    "            scale=np.sqrt(N/(N-1))  # rescaled t\n",
    "            )\n",
    "    \n",
    "    # reject or not\n",
    "    if abs(t_stat) >= crit_val:\n",
    "        reject = 1\n",
    "    else:\n",
    "        reject = 0\n",
    "    \n",
    "    return reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I can pack them into a function that generates Monte Carlo draws and calculates Bias, MSE, and rejection size.\n",
    "\n",
    "The draw is taken as follows:\n",
    "1. draw $x_{it} = \\zeta_{it}\\sim N(0,1)$;\n",
    "2. draw $u_{it} = \\epsilon_{it} \\sim N(0,\\sigma^2_{it}), \\sigma^2_{it} = \\lambda(0.1+x_{it}^{2})^{\\kappa}$;\n",
    "3. compute $y_{it}=\\beta x_{it} + u_{it}$.\n",
    "\n",
    "These can be obtained through element-wise matrix operation since all variables are in matrices of the same size to improve efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_draw(N, T, kappa, M):\n",
    "    \"\"\"\n",
    "    Generate a Monte Carlo draw for a given sample size N, time T, and kappa.\n",
    "    For the replication, impose beta = theta = 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # since these are relative to the infeasible ones contingent on each sample\n",
    "    total_bias = np.zeros([3,1])\n",
    "\n",
    "    # sum of squared error of each estimator and infeasible estimator\n",
    "    SE_est = np.zeros([3,1])\n",
    "    SE_inf = 0\n",
    "\n",
    "    # num of rejections\n",
    "    rej_count = np.zeros([3,1])\n",
    "\n",
    "    # compute true variance\n",
    "    true_var = var_true(kappa, T)\n",
    "\n",
    "    # draw M times for each design\n",
    "    for num in range(1,M):\n",
    "\n",
    "        # a matrix X of N(0,1) realizations of size N by T\n",
    "        X = np.random.normal(\n",
    "            loc=0, scale=1, size=(N,T)\n",
    "            )\n",
    "\n",
    "        # define kappa\n",
    "        if kappa==1:\n",
    "            Lambda = lambda1\n",
    "        elif kappa==-1:\n",
    "            Lambda = lambda2\n",
    "        \n",
    "        # a matrix X of N(0,sigma^2) realizations of size N by T\n",
    "        U = np.random.normal(\n",
    "            # mean and standard deviation are matrices because conditional on X\n",
    "            loc=np.zeros([N,T]), \n",
    "            scale=np.sqrt(Lambda * (0.1 + X**2) ** kappa),\n",
    "            size=(N,T)\n",
    "            )\n",
    "        \n",
    "        # define beta\n",
    "        beta = 0\n",
    "\n",
    "        # define Y\n",
    "        Y = beta*X + U\n",
    "\n",
    "        # NEXT, calculate FE estimator\n",
    "        X_tild = within(X)\n",
    "        Y_tild = within(Y)\n",
    "        beta_FE, res_FE = Fixed_Effect(X,Y)\n",
    "\n",
    "        # compute three types of HR variance estimator\n",
    "        HR_XS_hat = HR_XS(res_FE, X_tild)\n",
    "        HR_FE_hat = HR_FE(res_FE, X_tild)\n",
    "        cluster_hat = cluster(res_FE, X_tild)\n",
    "\n",
    "        # compute infeasible estimators\n",
    "        inf_var = var_inf(U, X_tild)\n",
    "        \n",
    "        # cumulative bias and RMSE\n",
    "        total_bias[0] += HR_XS_hat-true_var\n",
    "        total_bias[1] += HR_FE_hat-true_var\n",
    "        total_bias[2] += cluster_hat-true_var\n",
    "\n",
    "        SE_est[0] += (HR_XS_hat-true_var)**2\n",
    "        SE_est[1] += (HR_FE_hat-true_var)**2\n",
    "        SE_est[2] += (cluster_hat-true_var)**2\n",
    "\n",
    "        SE_inf += (inf_var - true_var)**2\n",
    "\n",
    "        # rejection count\n",
    "        rej_XS = hypo_test(HR_XS_hat, X_tild, beta_FE, beta, est_name='HR-XS')\n",
    "        rej_FE = hypo_test(HR_FE_hat, X_tild, beta_FE, beta, est_name='HR-FE')\n",
    "        rej_cluster = hypo_test(cluster_hat, X_tild, beta_FE, beta, est_name='cluster')\n",
    "\n",
    "        rej_count[0] += rej_XS\n",
    "        rej_count[1] += rej_FE\n",
    "        rej_count[2] += rej_cluster\n",
    "\n",
    "    # calculate total mean bias\n",
    "    bias = total_bias / M\n",
    "    bias_ratio = bias/true_var\n",
    "\n",
    "    # MSE ratio\n",
    "    MSE_est = SE_est / M\n",
    "    MSE_inf = SE_inf / M\n",
    "    MSE_ratio = MSE_est / MSE_inf\n",
    "\n",
    "    # rejection rate\n",
    "    rej_rate = rej_count/M\n",
    "    \n",
    "    return bias_ratio, MSE_ratio, rej_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Monte Carlo experiment is executed in the following block of the codes. I replicate Table 1 in the Stock and Watson paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-153-5b5c7b102320>:38: RuntimeWarning: invalid value encountered in reciprocal\n",
      "  scale=np.sqrt(Lambda * (0.1 + X**2) ** kappa),\n",
      "<ipython-input-152-1d23eab67d2b>:69: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t_stat = (beta_hat-beta) / np.sqrt(\n"
     ]
    }
   ],
   "source": [
    "# define design parameters\n",
    "Ns = [20, 100, 500]\n",
    "Ts = [5, 10, 20, 50]\n",
    "kappas = [-1, 1]\n",
    "\n",
    "NumDraws = 50000\n",
    "\n",
    "# define arrays to store outcomes\n",
    "output = np.zeros([4*6, 3*3+3])\n",
    "\n",
    "row = 0\n",
    "# loop\n",
    "for i in range(len(Ns)):\n",
    "    for j in range(len(Ts)):\n",
    "        for k in range(len(kappas)):\n",
    "            N = Ns[i]\n",
    "            T = Ts[j]\n",
    "            kappa = kappas[k]\n",
    "\n",
    "            # perform Monte Carlo draws\n",
    "            (bias_ratio, MSE_ratio, rej_rate) = MC_draw(\n",
    "                N=N, T=T, kappa=kappa, M=NumDraws\n",
    "                )\n",
    "            \n",
    "            # define labels\n",
    "            order = np.array([kappa, T, N], ndmin=2).T\n",
    "            temp = np.concatenate([\n",
    "                order, bias_ratio, MSE_ratio, rej_rate\n",
    "            ])\n",
    "\n",
    "            # store\n",
    "            output[row,:] = np.squeeze(temp)\n",
    "            row += 1\n",
    "            \n",
    "table = pd.DataFrame(data=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Bias Relative to True</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MSE Relative to Infeasible</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Size (Nominal Level 10%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>HR-XS</th>\n",
       "      <th>HR-FE</th>\n",
       "      <th>cluster</th>\n",
       "      <th>HR-XS</th>\n",
       "      <th>HR-FE</th>\n",
       "      <th>cluster</th>\n",
       "      <th>HR-XS</th>\n",
       "      <th>HR-FE</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kappa</th>\n",
       "      <th>T</th>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>20</th>\n",
       "      <td>-0.167018</td>\n",
       "      <td>-0.065950</td>\n",
       "      <td>-0.109483</td>\n",
       "      <td>0.701211</td>\n",
       "      <td>0.864549</td>\n",
       "      <td>0.994899</td>\n",
       "      <td>0.15294</td>\n",
       "      <td>0.13296</td>\n",
       "      <td>0.12620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.120409</td>\n",
       "      <td>-0.011068</td>\n",
       "      <td>-0.020611</td>\n",
       "      <td>0.936569</td>\n",
       "      <td>1.014448</td>\n",
       "      <td>1.196657</td>\n",
       "      <td>0.12908</td>\n",
       "      <td>0.10782</td>\n",
       "      <td>0.10666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.097951</td>\n",
       "      <td>0.014668</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>1.411187</td>\n",
       "      <td>1.055551</td>\n",
       "      <td>1.258072</td>\n",
       "      <td>0.12408</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.10220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
       "      <th>20</th>\n",
       "      <td>-0.086640</td>\n",
       "      <td>-0.027604</td>\n",
       "      <td>-0.073949</td>\n",
       "      <td>0.825495</td>\n",
       "      <td>0.925673</td>\n",
       "      <td>1.379785</td>\n",
       "      <td>0.12490</td>\n",
       "      <td>0.11422</td>\n",
       "      <td>0.10864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.053785</td>\n",
       "      <td>0.007884</td>\n",
       "      <td>-0.002088</td>\n",
       "      <td>0.928237</td>\n",
       "      <td>1.000293</td>\n",
       "      <td>1.478599</td>\n",
       "      <td>0.11298</td>\n",
       "      <td>0.10212</td>\n",
       "      <td>0.10100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.075081</td>\n",
       "      <td>-0.014710</td>\n",
       "      <td>-0.016728</td>\n",
       "      <td>1.682807</td>\n",
       "      <td>1.030170</td>\n",
       "      <td>1.553747</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.10110</td>\n",
       "      <td>0.10120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">20</th>\n",
       "      <th>20</th>\n",
       "      <td>-0.054336</td>\n",
       "      <td>-0.023669</td>\n",
       "      <td>-0.072848</td>\n",
       "      <td>0.920910</td>\n",
       "      <td>0.967471</td>\n",
       "      <td>2.013986</td>\n",
       "      <td>0.11354</td>\n",
       "      <td>0.10840</td>\n",
       "      <td>0.10674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.028093</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>-0.006545</td>\n",
       "      <td>0.967727</td>\n",
       "      <td>1.001680</td>\n",
       "      <td>2.104807</td>\n",
       "      <td>0.10798</td>\n",
       "      <td>0.10242</td>\n",
       "      <td>0.10266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.036313</td>\n",
       "      <td>-0.004893</td>\n",
       "      <td>-0.006970</td>\n",
       "      <td>1.320987</td>\n",
       "      <td>1.012897</td>\n",
       "      <td>2.142078</td>\n",
       "      <td>0.10706</td>\n",
       "      <td>0.10176</td>\n",
       "      <td>0.10196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">50</th>\n",
       "      <th>20</th>\n",
       "      <td>-0.019969</td>\n",
       "      <td>-0.007276</td>\n",
       "      <td>-0.057544</td>\n",
       "      <td>0.965326</td>\n",
       "      <td>0.986577</td>\n",
       "      <td>3.796865</td>\n",
       "      <td>0.10510</td>\n",
       "      <td>0.10302</td>\n",
       "      <td>0.10248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.015444</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>-0.013090</td>\n",
       "      <td>1.005910</td>\n",
       "      <td>1.002983</td>\n",
       "      <td>3.921963</td>\n",
       "      <td>0.10140</td>\n",
       "      <td>0.09924</td>\n",
       "      <td>0.09964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.011885</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>-0.001254</td>\n",
       "      <td>1.078416</td>\n",
       "      <td>1.004479</td>\n",
       "      <td>3.957466</td>\n",
       "      <td>0.10290</td>\n",
       "      <td>0.10082</td>\n",
       "      <td>0.10024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">-1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>20</th>\n",
       "      <td>0.333925</td>\n",
       "      <td>0.025212</td>\n",
       "      <td>-0.029188</td>\n",
       "      <td>3.270491</td>\n",
       "      <td>1.721855</td>\n",
       "      <td>1.989092</td>\n",
       "      <td>0.06080</td>\n",
       "      <td>0.10756</td>\n",
       "      <td>0.09296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.306204</td>\n",
       "      <td>-0.002298</td>\n",
       "      <td>-0.012990</td>\n",
       "      <td>8.326519</td>\n",
       "      <td>1.656508</td>\n",
       "      <td>2.029251</td>\n",
       "      <td>0.06006</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.09988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.324765</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>37.177129</td>\n",
       "      <td>1.626602</td>\n",
       "      <td>2.026086</td>\n",
       "      <td>0.06068</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.10080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
       "      <th>20</th>\n",
       "      <td>0.241587</td>\n",
       "      <td>0.009209</td>\n",
       "      <td>-0.044411</td>\n",
       "      <td>3.904450</td>\n",
       "      <td>1.550604</td>\n",
       "      <td>4.434379</td>\n",
       "      <td>0.06604</td>\n",
       "      <td>0.09922</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.236490</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>-0.006956</td>\n",
       "      <td>12.582775</td>\n",
       "      <td>1.506074</td>\n",
       "      <td>4.589099</td>\n",
       "      <td>0.06728</td>\n",
       "      <td>0.09872</td>\n",
       "      <td>0.09786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.230873</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>-0.004140</td>\n",
       "      <td>54.281702</td>\n",
       "      <td>1.502253</td>\n",
       "      <td>4.667522</td>\n",
       "      <td>0.06772</td>\n",
       "      <td>0.09904</td>\n",
       "      <td>0.09898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">20</th>\n",
       "      <th>20</th>\n",
       "      <td>0.149439</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>-0.044966</td>\n",
       "      <td>3.725885</td>\n",
       "      <td>1.377615</td>\n",
       "      <td>10.766868</td>\n",
       "      <td>0.07656</td>\n",
       "      <td>0.09846</td>\n",
       "      <td>0.09886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.139187</td>\n",
       "      <td>-0.003329</td>\n",
       "      <td>-0.013287</td>\n",
       "      <td>11.456702</td>\n",
       "      <td>1.362160</td>\n",
       "      <td>10.933831</td>\n",
       "      <td>0.07782</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.09974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.145593</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>55.548518</td>\n",
       "      <td>1.364820</td>\n",
       "      <td>10.880381</td>\n",
       "      <td>0.07846</td>\n",
       "      <td>0.09898</td>\n",
       "      <td>0.09908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">50</th>\n",
       "      <th>20</th>\n",
       "      <td>0.067084</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>-0.046242</td>\n",
       "      <td>2.684599</td>\n",
       "      <td>1.209185</td>\n",
       "      <td>31.977461</td>\n",
       "      <td>0.08838</td>\n",
       "      <td>0.09868</td>\n",
       "      <td>0.09900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.065462</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>-0.009816</td>\n",
       "      <td>8.132601</td>\n",
       "      <td>1.199180</td>\n",
       "      <td>32.411497</td>\n",
       "      <td>0.08832</td>\n",
       "      <td>0.09864</td>\n",
       "      <td>0.09922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.066681</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>-0.000865</td>\n",
       "      <td>36.540262</td>\n",
       "      <td>1.195063</td>\n",
       "      <td>32.382748</td>\n",
       "      <td>0.08880</td>\n",
       "      <td>0.09832</td>\n",
       "      <td>0.09796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bias Relative to True                      \\\n",
       "                             HR-XS     HR-FE   cluster   \n",
       "kappa T  n                                               \n",
       " 1    5  20              -0.167018 -0.065950 -0.109483   \n",
       "         100             -0.120409 -0.011068 -0.020611   \n",
       "         500             -0.097951  0.014668  0.013002   \n",
       "      10 20              -0.086640 -0.027604 -0.073949   \n",
       "         100             -0.053785  0.007884 -0.002088   \n",
       "         500             -0.075081 -0.014710 -0.016728   \n",
       "      20 20              -0.054336 -0.023669 -0.072848   \n",
       "         100             -0.028093  0.003573 -0.006545   \n",
       "         500             -0.036313 -0.004893 -0.006970   \n",
       "      50 20              -0.019969 -0.007276 -0.057544   \n",
       "         100             -0.015444 -0.002676 -0.013090   \n",
       "         500             -0.011885  0.000932 -0.001254   \n",
       "-1    5  20               0.333925  0.025212 -0.029188   \n",
       "         100              0.306204 -0.002298 -0.012990   \n",
       "         500              0.324765  0.009970  0.008042   \n",
       "      10 20               0.241587  0.009209 -0.044411   \n",
       "         100              0.236490  0.003100 -0.006956   \n",
       "         500              0.230873 -0.001936 -0.004140   \n",
       "      20 20               0.149439  0.006165 -0.044966   \n",
       "         100              0.139187 -0.003329 -0.013287   \n",
       "         500              0.145593  0.002108  0.000028   \n",
       "      50 20               0.067084  0.002064 -0.046242   \n",
       "         100              0.065462  0.000332 -0.009816   \n",
       "         500              0.066681  0.001454 -0.000865   \n",
       "\n",
       "             MSE Relative to Infeasible                       \\\n",
       "                                  HR-XS     HR-FE    cluster   \n",
       "kappa T  n                                                     \n",
       " 1    5  20                    0.701211  0.864549   0.994899   \n",
       "         100                   0.936569  1.014448   1.196657   \n",
       "         500                   1.411187  1.055551   1.258072   \n",
       "      10 20                    0.825495  0.925673   1.379785   \n",
       "         100                   0.928237  1.000293   1.478599   \n",
       "         500                   1.682807  1.030170   1.553747   \n",
       "      20 20                    0.920910  0.967471   2.013986   \n",
       "         100                   0.967727  1.001680   2.104807   \n",
       "         500                   1.320987  1.012897   2.142078   \n",
       "      50 20                    0.965326  0.986577   3.796865   \n",
       "         100                   1.005910  1.002983   3.921963   \n",
       "         500                   1.078416  1.004479   3.957466   \n",
       "-1    5  20                    3.270491  1.721855   1.989092   \n",
       "         100                   8.326519  1.656508   2.029251   \n",
       "         500                  37.177129  1.626602   2.026086   \n",
       "      10 20                    3.904450  1.550604   4.434379   \n",
       "         100                  12.582775  1.506074   4.589099   \n",
       "         500                  54.281702  1.502253   4.667522   \n",
       "      20 20                    3.725885  1.377615  10.766868   \n",
       "         100                  11.456702  1.362160  10.933831   \n",
       "         500                  55.548518  1.364820  10.880381   \n",
       "      50 20                    2.684599  1.209185  31.977461   \n",
       "         100                   8.132601  1.199180  32.411497   \n",
       "         500                  36.540262  1.195063  32.382748   \n",
       "\n",
       "             Size (Nominal Level 10%)                    \n",
       "                                HR-XS    HR-FE  cluster  \n",
       "kappa T  n                                               \n",
       " 1    5  20                   0.15294  0.13296  0.12620  \n",
       "         100                  0.12908  0.10782  0.10666  \n",
       "         500                  0.12408  0.10180  0.10220  \n",
       "      10 20                   0.12490  0.11422  0.10864  \n",
       "         100                  0.11298  0.10212  0.10100  \n",
       "         500                  0.11190  0.10110  0.10120  \n",
       "      20 20                   0.11354  0.10840  0.10674  \n",
       "         100                  0.10798  0.10242  0.10266  \n",
       "         500                  0.10706  0.10176  0.10196  \n",
       "      50 20                   0.10510  0.10302  0.10248  \n",
       "         100                  0.10140  0.09924  0.09964  \n",
       "         500                  0.10290  0.10082  0.10024  \n",
       "-1    5  20                   0.06080  0.10756  0.09296  \n",
       "         100                  0.06006  0.10210  0.09988  \n",
       "         500                  0.06068  0.10220  0.10080  \n",
       "      10 20                   0.06604  0.09922  0.09564  \n",
       "         100                  0.06728  0.09872  0.09786  \n",
       "         500                  0.06772  0.09904  0.09898  \n",
       "      20 20                   0.07656  0.09846  0.09886  \n",
       "         100                  0.07782  0.09938  0.09974  \n",
       "         500                  0.07846  0.09898  0.09908  \n",
       "      50 20                   0.08838  0.09868  0.09900  \n",
       "         100                  0.08832  0.09864  0.09922  \n",
       "         500                  0.08880  0.09832  0.09796  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort and beautify table of outcomes\n",
    "colnames = ['kappa', 'T', 'n', \n",
    "    'Bias ratio: HR-XS', 'Bias ratio: HR-FE', 'Bias ratio: cluster', \n",
    "    'MSE ratio: HR-XS', 'MSE ratio: HR-FE', 'MSE ratio: cluster', \n",
    "    'Rej size: HR-XS', 'Rej size: HR-FE', 'Rej size: cluster', \n",
    "    ]\n",
    "\n",
    "# change column names and indexes\n",
    "table.columns = colnames\n",
    "\n",
    "# set integer to indexes\n",
    "table[['kappa', 'T', 'n']] = table[['kappa', 'T', 'n']].astype(int)\n",
    "table = table.sort_values(by=['kappa', 'T', 'n'],ascending=[False, True, True]).set_index(['kappa', 'T', 'n'])\n",
    "table.columns = pd.MultiIndex.from_product([\n",
    "    ['Bias Relative to True', 'MSE Relative to Infeasible', 'Size (Nominal Level 10%)'], ['HR-XS', 'HR-FE', 'cluster']\n",
    "    ])\n",
    "\n",
    "# print\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Indeed, the above exercise replicates the Monte Carlo report of Stock and Watson (2008) and produces results of the same magnitude and directions. This also verifies my codes. \n",
    "\n",
    "The bias of the usually used $\\hat{\\Sigma}^{\\text{HR-XS}}$ estimator can have a large and persistent bias that persists even if $n$ increases. And the large bias can produce a large MSE. But in some cases its MSE is smaller than the MSE of the infeasible estimator when $n$ and $T$ are small. This illustrates a bias-variance trade-off.\n",
    "\n",
    "The proposed bias correction estimator $\\hat{\\Sigma}^{\\text{HR-FE}}$ works - the relative bias in all cases are small and in most cases its MSE is very close to the one of the infeasible estimator.\n",
    "\n",
    "The ratio of the MSE of the cluster estimator as expected do not converge to 1 as $n$ increases for a fixed $T$. The rejection results also confirm the conjecture that variance estimators with less bias would produce better size for the hypothesis test $\\beta = 0$. When $\\hat{\\Sigma}^{\\text{HR-XS}}$ is biased up, the test rejects too little, and when $\\hat{\\Sigma}^{\\text{HR-XS}}$ is biased down, the test rejects too often. When $T$ is small, the magnitude of distortion can be quite considerable.\n",
    "\n",
    "\n",
    "## Reference\n",
    "Stock, J.H. and Watson, M.W. (2008), Heteroskedasticity-Robust Standard Errors for Fixed Effects Panel Data Regression. Econometrica, 76: 155-174."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ec93b0f91a52b17860126035fd0fe6f838541963af8bd7d1baca447731ef625"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
